\relax 
\providecommand*{\memsetcounter}[2]{}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {1}Introduction}{1}}
\citation{rasmussen2006}
\citation{wiki:gauss}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The classical regression problem. Left: Given six noisy data point we are interested in estimating the value of a seventh point at $x_\star =1.4$. Right: The solution to the problem. The shaded area show the $2\sigma $ confidence interval for the value of the underlying function, while the green point show the predicted function value and $1\sigma $ uncertainty of the underlying function at $x_\star =1.4$. The dashed line shows the actual function from which the observations were drawn in the first place.\relax }}{2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:regression}{{\M@TitleReference {1}{Introduction}}{2}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {2}Theory}{2}}
\newlabel{sec:theory}{{\M@TitleReference {2}{Theory}}{2}}
\citation{wiki:gram}
\citation{rasmussen2006}
\citation{rasmussen2006}
\citation{gregory2005}
\citation{rasmussen2006}
\newlabel{eq:se}{{\M@TitleReference {1}{Theory}}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Bayesian Inference}{3}}
\citation{rasmussen2006}
\newlabel{eq:likelihood}{{\M@TitleReference {2}{Bayesian Inference}}{4}}
\newlabel{eq:prior}{{\M@TitleReference {3}{Bayesian Inference}}{4}}
\newlabel{eq:bayes}{{\M@TitleReference {4}{Bayesian Inference}}{4}}
\newlabel{eq:marginal}{{\M@TitleReference {5}{Bayesian Inference}}{4}}
\newlabel{eq:pred}{{\M@TitleReference {6}{Bayesian Inference}}{4}}
\newlabel{eq:pred2}{{\M@TitleReference {7}{Bayesian Inference}}{4}}
\citation{rasmussen2006}
\citation{press2007}
\citation{press2007}
\citation{rasmussen2006}
\newlabel{eq:loglike}{{\M@TitleReference {8}{Bayesian Inference}}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Left: Four samples drawn from the prior distribution \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces \ref  {eq:prior}\unskip \@@italiccorr )}}, using a covariance matrix generated from a Squared exponential covariance function \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces \ref  {eq:se}\unskip \@@italiccorr )}}. The shaded area gives the $2\sigma $ uncertainty of the prior distribution. Right: Same four samples this time drawn from the predictive distribution \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces \ref  {eq:pred2}\unskip \@@italiccorr )}}, conditioned on two noiseless data points (in the case of no noise GPR is essentially the same as the interpolation scheme known as \emph  {Kriging} \cite  [Chapter~3]{press2007}). The uncertainty is again $2\sigma $, and the dashed line gives the mean prediction.\relax }}{5}}
\newlabel{fig:prediction}{{\M@TitleReference {2}{Bayesian Inference}}{5}}
\newlabel{eq:hyper}{{\M@TitleReference {9}{Bayesian Inference}}{5}}
\citation{rasmussen2006}
\citation{wiki:chol}
\citation{rasmussen2006}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {3}Description of Software}{6}}
\newlabel{sec:description}{{\M@TitleReference {3}{Description of Software}}{6}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {4}Tests}{8}}
\newlabel{sec:tests}{{\M@TitleReference {4}{Tests}}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Same as Figure~\ref  {fig:regression}, but with wider range.\relax }}{8}}
\newlabel{fig:test1}{{\M@TitleReference {3}{Tests}}{8}}
\citation{rasmussen2006}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Top: Data drawn from a GP with hyperparameters $(\ell ,\sigma _f,\sigma _n)=(1,1,0.1)$, and predictions using the same hyperparameters. Bottom Left: Same data but predictions using hyperparameters $(0.3,0.5,0.0005)$. Bottom Right: Same data but predictions using hyperparamters $(3,1,0.9)$\relax }}{9}}
\newlabel{fig:varyhyper}{{\M@TitleReference {4}{Tests}}{9}}
\newlabel{eq:per}{{\M@TitleReference {10}{Tests}}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Left: The data and predictions ahead in time. Looking at the data the predictions looks reasonable for a while until they start dropping although there's nothing in the data to suggest this. Right: Predictions of the Squared Exponential, and periodic term.\relax }}{10}}
\newlabel{fig:composite}{{\M@TitleReference {5}{Tests}}{10}}
\bibstyle{plain}
\bibdata{cit.bib}
\bibcite{gregory2005}{1}
\bibcite{press2007}{2}
\bibcite{rasmussen2006}{3}
\bibcite{wiki:chol}{4}
\bibcite{wiki:gram}{5}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {5}Example}{11}}
\newlabel{sec:example}{{\M@TitleReference {5}{Example}}{11}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {6}Discussion \& Conclusion}{11}}
\newlabel{sec:discussion}{{\M@TitleReference {6}{Discussion \& Conclusion}}{11}}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{11}}
\bibcite{wiki:gauss}{6}
\memsetcounter{lastsheet}{12}
\memsetcounter{lastpage}{12}
